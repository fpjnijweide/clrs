{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from run import main\n",
    "from absl import flags\n",
    "from absl import app\n",
    "import sys\n",
    "\n",
    "flags.DEFINE_string('algorithm', 'lcs_length', 'Which algorithm to run.')\n",
    "flags.DEFINE_integer('seed', 42, 'Random seed to set')\n",
    "\n",
    "flags.DEFINE_integer('batch_size', 16, 'Batch size used for training.')\n",
    "flags.DEFINE_boolean('chunked_training', False,\n",
    "                     'Whether to use chunking for training.')\n",
    "flags.DEFINE_integer('chunk_length', 100,\n",
    "                     'Time chunk length used for training (if '\n",
    "                     '`chunked_training` is True.')\n",
    "flags.DEFINE_integer('train_items', 320000,\n",
    "                     'Number of items (i.e., individual examples, possibly '\n",
    "                     'repeated) processed during training. With non-chunked'\n",
    "                     'training, this is the number of training batches times '\n",
    "                     'the number of training steps. For chunked training, '\n",
    "                     'as many chunks will be processed as needed to get these '\n",
    "                     'many full examples.')\n",
    "flags.DEFINE_integer('eval_every', 320,\n",
    "                     'Logging frequency (in training examples).')\n",
    "flags.DEFINE_boolean('verbose_logging', False, 'Whether to log aux losses.')\n",
    "\n",
    "flags.DEFINE_integer('hidden_size', 128,\n",
    "                     'Number of hidden size units of the model.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Learning rate to use.')\n",
    "flags.DEFINE_float('dropout_prob', 0.0, 'Dropout rate to use.')\n",
    "flags.DEFINE_float('hint_teacher_forcing_noise', 0.5,\n",
    "                   'Probability that rematerialized hints are encoded during '\n",
    "                   'training instead of ground-truth teacher hints. Only '\n",
    "                   'pertinent in encoded_decoded modes.')\n",
    "flags.DEFINE_integer('nb_heads', 1, 'Number of heads for GAT processors')\n",
    "\n",
    "flags.DEFINE_enum('hint_mode', 'encoded_decoded_nodiff',\n",
    "                  ['encoded_decoded', 'decoded_only',\n",
    "                   'encoded_decoded_nodiff', 'decoded_only_nodiff',\n",
    "                   'none'],\n",
    "                  'How should hints be used? Note, each mode defines a '\n",
    "                  'separate task, with various difficulties. `encoded_decoded` '\n",
    "                  'requires the model to explicitly materialise hint sequences '\n",
    "                  'and therefore is hardest, but also most aligned to the '\n",
    "                  'underlying algorithmic rule. Hence, `encoded_decoded` '\n",
    "                  'should be treated as the default mode for our benchmark. '\n",
    "                  'In `decoded_only`, hints are only used for defining '\n",
    "                  'reconstruction losses. Often, this will perform well, but '\n",
    "                  'note that we currently do not make any efforts to '\n",
    "                  'counterbalance the various hint losses. Hence, for certain '\n",
    "                  'tasks, the best performance will now be achievable with no '\n",
    "                  'hint usage at all (`none`). The `no_diff` variants '\n",
    "                  'try to predict all hint values instead of just the values '\n",
    "                  'that change from one timestep to the next.')\n",
    "\n",
    "flags.DEFINE_boolean('use_ln', True,\n",
    "                     'Whether to use layer normalisation in the processor.')\n",
    "flags.DEFINE_string('use_memory', \"NTM\",\n",
    "                    'Whether to insert memory after message passing.')\n",
    "flags.DEFINE_enum(\n",
    "    'processor_type', 'gatv2',\n",
    "    ['deepsets', 'mpnn', 'pgn', 'pgn_mask',\n",
    "     'gat', 'gatv2', 'gat_full', 'gatv2_full',\n",
    "     'memnet_full', 'memnet_masked'],\n",
    "    'The processor type to use.')\n",
    "\n",
    "flags.DEFINE_string('checkpoint_path', '/tmp/CLRS30',\n",
    "                    'Path in which checkpoints are saved.')\n",
    "flags.DEFINE_string('dataset_path', '/tmp/CLRS30',\n",
    "                    'Path in which dataset is stored.')\n",
    "flags.DEFINE_boolean('freeze_processor', False,\n",
    "                     'Whether to freeze the processor of the model.')\n",
    "flags.DEFINE_integer('memory_size', 20,\n",
    "                     'Size of differentiable data structure memory.')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "FLAGS(sys.argv)\n",
    "GAT_BEST = [\n",
    "    'dfs',\n",
    "    'jarvis_march',\n",
    "    'kmp_matcher',\n",
    "    'lcs_length',\n",
    "    'quickselect',\n",
    "    'task_scheduling'\n",
    "]\n",
    "# MPNN algos\n",
    "MPNN_BEST = [\n",
    "    'articulation_points',\n",
    "    'activity_selector',\n",
    "    'bfs',\n",
    "    'bridges',\n",
    "    'dijkstra',\n",
    "    'graham_scan',\n",
    "    'mst_kruskal',\n",
    "    'mst_prim',\n",
    "    'naive_string_matcher',\n",
    "    'segments_intersect',\n",
    "    'strongly_connected_components',\n",
    "]\n",
    "PGN_best = [\n",
    "    'activity_selector',\n",
    "    'bellman_ford',\n",
    "    'binary_search',\n",
    "    'dag_shortest_paths',\n",
    "    'find_maximum_subarray_kadane',\n",
    "    'floyd_warshall',\n",
    "    'matrix_chain_order',\n",
    "    'minimum',\n",
    "    'mst_prim',\n",
    "    'optimal_bst',\n",
    "    'quickselect',\n",
    "    'strongly_connected_components',\n",
    "    'task_scheduling',\n",
    "    'topological_sort',\n",
    "]\n",
    "\n",
    "# memory_type = \"NTM\"\n",
    "# model=\"gatv2\"\n",
    "# memory_size=20\n",
    "\n",
    "FLAGS.memory_size=100\n",
    "for model in [\"gatv2\",\"mpnn\"]:\n",
    "    FLAGS.processor_type = model\n",
    "    if FLAGS.processor_type==\"gatv2\" or FLAGS.processor_type==\"gat\":\n",
    "        algo_list=GAT_BEST\n",
    "    elif FLAGS.processor_type==\"mpnn\":\n",
    "        algo_list = MPNN_BEST\n",
    "    else:\n",
    "        algo_list = PGN_best\n",
    "\n",
    "    for algo in algo_list:\n",
    "        FLAGS.algorithm = algo\n",
    "\n",
    "        with open(\"results.txt\") as myfile:\n",
    "            txt = myfile.read()\n",
    "            if not (f\"{algo}_{FLAGS.processor_type}_{FLAGS.use_memory}_{FLAGS.memory_size}\" in txt) and not (f\"{algo}_best_{FLAGS.processor_type}_{FLAGS.use_memory}_{FLAGS.memory_size}\" in txt) :\n",
    "                print(f\"running with specs: {algo}, {FLAGS.use_memory}, {FLAGS.processor_type}, {FLAGS.memory_size}\")\n",
    "                app.run(main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
